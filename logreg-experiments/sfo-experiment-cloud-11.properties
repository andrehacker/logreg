# GLOBAL
experiment_name = sfo

# on which system to run the test: hadoop or ozone
sut = ozone

# Control variables
deploy_sut = false
start_sut = true
run_experiments = true
stop_sut = true

# commaseparated (1-25) (stratosphere starts with cloud-12)
dops = 8

# make multiple runs of the same experiment to ensure statistical significance
repetitions = 1

# sfo specific
add_per_iteration = 1

dataset_name = rcv1-ecat-test

#
# HADOOP EXPERIMENT
#

jar_hadoop = /home/ahacker/experiments/jars/logreg-mapred-0.0.1-SNAPSHOT-job.jar
# Input
input_local_hadoop = file:///data/users/ahacker/datasets/rcv1-v2/sequencefiles/lyrl2004_vectors_ecat_train.seq
input_hadoop = hdfs://cloud-11:45010/experiments/input/rcv1/lyrl2004_vectors_ecat_train.seq
#CCAT=33, ECAT=59, GCAT=70, MCAT=102
label_index_ozone = 59
# Output
output_train_hadoop = hdfs://cloud-11:45010/experiments/output/output-sfo-train
output_test_hadoop = hdfs://cloud-11:45010/experiments/output/output-sfo-test

#
# OZONE EXPERIMENT
#

jar_ozone  = /home/ahacker/experiments/jars/logreg-pact-0.0.1-SNAPSHOT-job.jar
# Input / Output
input_local_ozone = file:///data/users/ahacker/datasets/libsvm-rcv1v2-topics/rcv1_topics_test.svm
input_ozone = hdfs://cloud-11:45010/experiments/input/rcv1/rcv1_topics_test.svm
# Output
output_ozone = hdfs://cloud-11:45010/output-sfo-pact
