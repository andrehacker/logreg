# GLOBAL
experiment_name = sfo

# commaseparated, on which system to run the test: hadoop or ozone
sut = ozone

# commaseparated
repetitions = 1

# make multiple runs of the same experiment to ensure statistical significance
dops = 1

# sfo specific
add_per_iteration = 1

# Jobs
jar_hadoop = /home/andre/dev/logreg-repo/logreg-mapred/target/logreg-mapred-0.0.1-SNAPSHOT-job.jar
jar_ozone  = /home/andre/dev/logreg-repo/logreg-pact/target/logreg-pact-0.0.1-SNAPSHOT-job.jar

# INPUT
dataset_name = rcv1small
# INPUT HADOOP
input_local_hadoop = file:///home/andre/dev/datasets/RCV1-v2/sequencefiles/lyrl2004_vectors_ecat_train.seq
input_hadoop = hdfs://localhost:9000/experiments/input/rcv1/lyrl2004_vectors_ecat_train.seq
# INPUT OZONE
input_local_ozone = file:///home/andre/dev/datasets/libsvm-rcv1v2-topics/rcv1_topics_train_1000.svm
input_ozone = hdfs://localhost:9000/experiments/input/rcv1/rcv1_topics_train_1000.svm
#CCAT=33, ECAT=59, GCAT=70, MCAT=102
label_index_ozone = 59

# OUTPUT
output_train_hadoop = hdfs://localhost:9000/experiments/output/output-sfo-train
output_test_hadoop = hdfs://localhost:9000/experiments/output/output-sfo-test

output_ozone = hdfs://localhost:9000/output-sfo-pact
