10:02:06,823 INFO  de.tuberlin.dima.experiments.ml.experiments.SFOExperiment$    - Loaded Property: experiment_name = sfo
10:02:06,826 INFO  de.tuberlin.dima.experiments.ml.experiments.SFOExperiment$    - Loaded Property: sut = hadoop
10:02:06,903 INFO  de.tuberlin.dima.experiments.ml.experiments.SFOExperiment$    - Loaded Property: jar_hadoop = /home/andre/dev/logreg-repo/logreg-mapred/target/logreg-mapred-0.0.1-SNAPSHOT-job.jar
10:02:06,904 INFO  de.tuberlin.dima.experiments.ml.experiments.SFOExperiment$    - Loaded Property: input_local_hadoop = /home/andre/dev/datasets/RCV1-v2/sequencefiles/lyrl2004_vectors_ecat_train_1000.seq
10:02:06,904 INFO  de.tuberlin.dima.experiments.ml.experiments.SFOExperiment$    - Loaded Property: input_hadoop = experiments/input/rcv1/lyrl2004_vectors_ecat_train_1000.seq
10:02:06,905 INFO  de.tuberlin.dima.experiments.ml.experiments.SFOExperiment$    - Loaded Property: output_train_hadoop = output-sfo-train
10:02:06,905 INFO  de.tuberlin.dima.experiments.ml.experiments.SFOExperiment$    - Loaded Property: output_test_hadoop = output-sfo-test
10:02:06,905 INFO  de.tuberlin.dima.experiments.ml.experiments.SFOExperiment$    - Loaded Property: jar_ozone = /home/andre/dev/logreg-repo/logreg-pact/target/logreg-pact-0.0.1-SNAPSHOT-job.jar
10:02:06,906 INFO  de.tuberlin.dima.experiments.ml.experiments.SFOExperiment$    - Loaded Property: input_local_ozone = file:///home/andre/dev/datasets/libsvm-rcv1v2-topics/rcv1_topics_train_1000.svm
10:02:06,906 INFO  de.tuberlin.dima.experiments.ml.experiments.SFOExperiment$    - Loaded Property: input_ozone = hdfs://localhost:9000/experiments/input/rcv1/rcv1_topics_train_1000.svm
10:02:07,011 INFO  de.tuberlin.dima.experiments.ml.experiments.SFOExperiment$    - Loaded Property: label_index_ozone = 59
10:02:07,012 INFO  de.tuberlin.dima.experiments.ml.experiments.SFOExperiment$    - Loaded Property: output_ozone = hdfs://localhost:9000/output-sfo-pact
10:02:07,013 INFO  de.tuberlin.dima.experiments.ml.experiments.SFOExperiment$    - Loaded Property: hadoop_jobtracker_address = localhost:9001
10:02:07,013 INFO  de.tuberlin.dima.experiments.ml.experiments.SFOExperiment$    - Loaded Property: hdfs_address = hdfs://localhost:9000
10:02:07,046 INFO  de.tuberlin.dima.experiments.ml.experiments.SFOExperiment$    - Loaded Property: job_manager_address = localhost
10:02:07,046 INFO  de.tuberlin.dima.experiments.ml.experiments.SFOExperiment$    - Loaded Property: job_manager_port = 6123
10:02:07,047 INFO  de.tuberlin.dima.experiments.ml.experiments.SFOExperiment$    - Loaded Property: ozone_conf = /home/andre/experiments/suts/stratosphere-0.2-ozone/conf
10:02:07,049 INFO  de.tuberlin.dima.experiments.ml.experiments.SFOExperiment$    - Loaded Property: dops = 1
10:02:07,055 INFO  de.tuberlin.dima.experiments.ml.experiments.SFOExperiment$    - Loaded Property: repetitions = 1
10:02:07,056 INFO  de.tuberlin.dima.experiments.ml.experiments.SFOExperiment$    - Loaded Property: add_per_iteration = 1
10:02:07,056 INFO  de.tuberlin.dima.experiments.ml.experiments.SFOExperiment$    - Loaded Property: dataset_name = rcv1small
10:02:07,068 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - Loaded Property: is_yarn = false
10:02:07,068 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - Loaded Property: all_slaves = /home/andre/dev/logreg-repo/logreg-experiments/conf-templates/andre-sam-ubuntu/all_slaves
10:02:07,068 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - Loaded Property: user = andre
10:02:07,068 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - Loaded Property: group = andre
10:02:07,068 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - Loaded Property: hadoop_tar = /home/andre/experiments/setups/hadoop-1.2.1-bin.tar.gz
10:02:07,069 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - Loaded Property: hadoop_home = /home/andre/experiments/suts/hadoop-1.2.1
10:02:07,069 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - Loaded Property: hadoop_conf_template = /home/andre/dev/logreg-repo/logreg-experiments/conf-templates/andre-sam-ubuntu/hadoop-1.2.1
10:02:07,069 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - Loaded Property: hadoop_conf = /home/andre/experiments/suts/hadoop-1.2.1/conf
10:02:07,069 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - Loaded Property: hadoop_log = /home/andre/experiments/suts/hadoop-1.2.1/logs
10:02:07,069 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - Loaded Property: hadoop_slaves_file = /home/andre/experiments/suts/hadoop-1.2.1/conf/slaves
10:02:07,070 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - Loaded Property: hadoop_pid_folder = /tmp
10:02:07,070 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - Loaded Property: hdfs_data_dir = /data/hdfs/data
10:02:07,070 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - Loaded Property: hdfs_address = hdfs://localhost:9000
10:02:07,070 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - Loaded Property: hdfs_namenode_hostname = andre-sam-ubuntu
10:02:07,070 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - Loaded Property: experiment_log_dir = /home/andre/experiments/log
10:02:07,072 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - -------------------- DEPLOY HDFS (incl. Hadoop) --------------------

10:02:07,072 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - Check if hdfs namenode is running
10:02:07,079 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - - exec (bash): kill -0 17797
10:02:07,096 INFO  de.tuberlin.dima.experiments.HadoopSUT                        -  - result strerr: /bin/bash: Zeile 0: kill: (17797) - Kein passender Prozess gefunden

10:02:07,097 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - - Removing old SUT home folder
10:02:07,098 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - - exec (bash): rm -Rf /home/andre/experiments/suts/hadoop-1.2.1
10:02:07,153 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - - Unpacking tar
10:02:07,153 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - - exec (bash): tar -xzvf /home/andre/experiments/setups/hadoop-1.2.1-bin.tar.gz -C /home/andre/experiments/suts
10:02:08,199 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - Copy config files from /home/andre/dev/logreg-repo/logreg-experiments/conf-templates/andre-sam-ubuntu/hadoop-1.2.1 to /home/andre/experiments/suts/hadoop-1.2.1/conf
10:02:08,229 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - - Setting proper rights in SUT home
10:02:08,229 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - - exec (bash): chown -R andre:andre /home/andre/experiments/suts/hadoop-1.2.1
10:02:08,240 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - - exec (bash): find /home/andre/experiments/suts/hadoop-1.2.1 -type f | xargs -I{} chmod g+w {}
10:02:08,789 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - - exec (bash): find /home/andre/experiments/suts/hadoop-1.2.1 -type d | xargs -I{} chmod g+w {}
10:02:08,937 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - Copy additional libs to sut's lib dir
10:02:08,937 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - - exec (bash): cp /home/andre/dev/logreg-repo/logreg-experiments/lib-templates/hadoop-1.2.1/* /home/andre/experiments/suts/hadoop-1.2.1/lib/
10:02:08,961 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - -------------------- ADAPT HADOOP SLAVES --------------------

10:02:08,963 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - Write current slaves (1) to /home/andre/experiments/suts/hadoop-1.2.1/conf/slaves:
10:02:08,968 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - - localhost
10:02:08,968 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - -------------------- HDFS FORMAT START WAIT --------------------

10:02:08,968 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - - exec (bash): rm -Rf /home/andre/experiments/suts/hadoop-1.2.1/logs/hadoop-andre-*node-*.log*
10:02:08,977 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - Delete /data/hdfs/data on slave localhost
10:02:08,977 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - - exec (bash): ssh andre@localhost 'rm -Rf /data/hdfs/data'
10:02:09,416 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - - exec (bash): /home/andre/experiments/suts/hadoop-1.2.1/bin/hadoop namenode -format -force
10:02:11,807 INFO  de.tuberlin.dima.experiments.HadoopSUT                        -  - result strerr: 13/08/20 10:02:09 INFO namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = andre-sam-ubuntu/127.0.1.1
STARTUP_MSG:   args = [-format, -force]
STARTUP_MSG:   version = 1.2.1
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-1.2 -r 1503152; compiled by 'mattf' on Mon Jul 22 15:23:09 PDT 2013
STARTUP_MSG:   java = 1.6.0_43
************************************************************/
13/08/20 10:02:10 INFO util.GSet: Computing capacity for map BlocksMap
13/08/20 10:02:10 INFO util.GSet: VM type       = 64-bit
13/08/20 10:02:10 INFO util.GSet: 2.0% max memory = 932118528
13/08/20 10:02:10 INFO util.GSet: capacity      = 2^21 = 2097152 entries
13/08/20 10:02:10 INFO util.GSet: recommended=2097152, actual=2097152
13/08/20 10:02:10 INFO namenode.FSNamesystem: fsOwner=andre
13/08/20 10:02:10 INFO namenode.FSNamesystem: supergroup=supergroup
13/08/20 10:02:10 INFO namenode.FSNamesystem: isPermissionEnabled=true
13/08/20 10:02:10 INFO namenode.FSNamesystem: dfs.block.invalidate.limit=100
13/08/20 10:02:10 INFO namenode.FSNamesystem: isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
13/08/20 10:02:10 INFO namenode.FSEditLog: dfs.namenode.edits.toleration.length = 0
13/08/20 10:02:10 INFO namenode.NameNode: Caching file names occuring more than 10 times 
13/08/20 10:02:11 INFO common.Storage: Image file /data/hdfs/name/current/fsimage of size 111 bytes saved in 0 seconds.
13/08/20 10:02:11 INFO namenode.FSEditLog: closing edit log: position=4, editlog=/data/hdfs/name/current/edits
13/08/20 10:02:11 INFO namenode.FSEditLog: close success: truncate to 4, editlog=/data/hdfs/name/current/edits
13/08/20 10:02:11 INFO common.Storage: Storage directory /data/hdfs/name has been successfully formatted.
13/08/20 10:02:11 INFO namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at andre-sam-ubuntu/127.0.1.1
************************************************************/

10:02:11,807 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - - exec (bash): /home/andre/experiments/suts/hadoop-1.2.1/bin/start-dfs.sh
10:02:15,645 INFO  de.tuberlin.dima.experiments.HadoopSUT                        -  - result stdout: starting namenode, logging to /home/andre/experiments/suts/hadoop-1.2.1/libexec/../logs/hadoop-andre-namenode-andre-sam-ubuntu.out
localhost: starting datanode, logging to /home/andre/experiments/suts/hadoop-1.2.1/libexec/../logs/hadoop-andre-datanode-andre-sam-ubuntu.out
localhost: starting secondarynamenode, logging to /home/andre/experiments/suts/hadoop-1.2.1/libexec/../logs/hadoop-andre-secondarynamenode-andre-sam-ubuntu.out

10:02:15,646 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - Waiting for safe mode to be off
10:02:15,646 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - - exec (bash): /home/andre/experiments/suts/hadoop-1.2.1/bin/hadoop dfsadmin -safemode get
10:02:19,914 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - - Safemode-OFF=true
10:02:20,415 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - Waiting for 1 datanodes to connect
10:02:20,434 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - - Nodes connected=0
10:02:21,437 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - - Nodes connected=0
10:02:22,441 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - - Nodes connected=0
10:02:23,444 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - - Nodes connected=0
10:02:24,447 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - - Nodes connected=0
10:02:25,449 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - - Nodes connected=0
10:02:26,452 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - - Nodes connected=0
10:02:27,454 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - - Nodes connected=0
10:02:28,457 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - - Nodes connected=0
10:02:29,460 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - - Nodes connected=0
10:02:30,464 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - - Nodes connected=0
10:02:31,467 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - - Nodes connected=1
10:02:32,471 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - -------------------- LOAD DATA --------------------

10:02:32,476 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - Copy /home/andre/dev/datasets/RCV1-v2/sequencefiles/lyrl2004_vectors_ecat_train_1000.seq to experiments/input/rcv1/lyrl2004_vectors_ecat_train_1000.seq using hdfs hdfs://localhost:9000
10:02:33,909 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - -------------------- START MAPRED --------------------

10:02:33,910 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - Check if jobtracker is running
10:02:33,910 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - - exec (bash): kill -0 18505
10:02:33,920 INFO  de.tuberlin.dima.experiments.HadoopSUT                        -  - result strerr: /bin/bash: Zeile 0: kill: (18505) - Kein passender Prozess gefunden

10:02:33,920 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - - exec (bash): rm -Rf /home/andre/experiments/suts/hadoop-1.2.1/logs/hadoop-andre-*tracker-*.log*
10:02:33,925 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - - exec (bash): /home/andre/experiments/suts/hadoop-1.2.1/bin/start-mapred.sh
10:02:36,390 INFO  de.tuberlin.dima.experiments.HadoopSUT                        -  - result stdout: starting jobtracker, logging to /home/andre/experiments/suts/hadoop-1.2.1/libexec/../logs/hadoop-andre-jobtracker-andre-sam-ubuntu.out
localhost: starting tasktracker, logging to /home/andre/experiments/suts/hadoop-1.2.1/libexec/../logs/hadoop-andre-tasktracker-andre-sam-ubuntu.out

10:02:36,390 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - Waiting for 1 nodes (tasktracker or nodemanager) to connect
10:02:36,391 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - - Nodes connected=0
10:02:37,393 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - - Nodes connected=0
10:02:38,395 INFO  de.tuberlin.dima.experiments.HadoopSUT                        - - Nodes connected=0
